{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:08:57.968556Z",
     "start_time": "2023-07-11T17:08:56.454456Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Summary\n",
    "\n",
    "The script taps into the Totango Touchpoints API (documentation available [here](https://support.totango.com/hc/en-us/articles/115000597266-Touchpoints-API))  to archive all touchpoints, notes, and alerts. It starts with obtaining a full client list, then sequentially queries the Touchpoints API for each client to collect associated touchpoints. Post data gathering, basic data cleaning is performed for the readiness of the data for subsequent operations or backup.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. Utilizes the Totango Touchpoints API for data extraction.\n",
    "<br>\n",
    "2. Gathers a comprehensive list of all clients for processing.\n",
    "<br>\n",
    "3. Seqntially pulls all touchpoints, notes, and alerts for each client.\n",
    "<br>\n",
    "4. Conducts basic data cleaning post data extraction.\n",
    "<br>   \n",
    "5. Aids in the process of backing up crucial client interaction data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:22:29.843782Z",
     "start_time": "2023-07-11T17:22:28.664206Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import pyodbc\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import event\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:22:30.383445Z",
     "start_time": "2023-07-11T17:22:30.370924Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#the autherization token needs to be obtained from totango and passed in the header\n",
    "headers = {\n",
    "    'app-token':\n",
    "    'ENTER YOUR TOKEN HERE',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Client List of the Totango Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code block, we're going through a range of numbers from 0 to 15000 (Depends on the n, increasing by 1000 at each step. At each step, we're creating a new query with the current offset being the number i. This query is then sent to a URL via a POST request. We get the JSON response\n",
    "\n",
    "The use of an f-string in this case helps to inject the value of i directly into the string, making it more readable and efficient than string concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:22:47.249077Z",
     "start_time": "2023-07-11T17:22:32.927286Z"
    }
   },
   "outputs": [],
   "source": [
    "clientlist = pd.DataFrame()\n",
    "for i in range(0, 16000, 1000):\n",
    "    data =  {\n",
    "    'query':\n",
    "    f'{{\"terms\":[{{\"type\":\"string\",\"term\":\"status_group\",\"in_list\":[\"paying\"]}},{{\"type\":\"string_attribute\",\"attribute\":\"Account Type\",\"query_term_id\":\"account_type\",\"in_list\":[\"Client\"]}}],\"count\":1000,\"offset\":{i},\"fields\":[],\"scope\":\"all\"}}'\n",
    "    }\n",
    "    response = requests.post(\n",
    "    'https://app.totango.com/api/v1/search/accounts',\n",
    "    headers=headers,data=data)    \n",
    "    data = response.json()\n",
    "    data = data['response']['accounts']['hits']\n",
    "    data = pd.json_normalize(data)\n",
    "    clientlist = clientlist.append(data, ignore_index=True)\n",
    "    \n",
    "print(\"Total Number of Clients Found in Totango\", len(clientlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Touchpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block performs the following steps:\n",
    "\n",
    "1. Initializes an empty DataFrame named df_.\n",
    "\n",
    "2. Sends a GET request to the 'https://app.totango.com/api/v2/events/' endpoint with a specified account_id as a parameter and specific headers. This is intended to fetch data related to a specific account.\n",
    "\n",
    "3. Parses the JSON response from the API request.\n",
    "\n",
    "4. Converts the parsed JSON response to a pandas DataFrame using the pd.json_normalize() function. This flattens the JSON structure into a tabular format.\n",
    "\n",
    "5. Drops all rows in the initialized DataFrame df_ using the drop() function. This is done to ensure that the DataFrame is empty and clean for subsequent use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:23:46.137951Z",
     "start_time": "2023-07-11T17:23:45.049607Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize an empty dataframe to hold the touchpoints data\n",
    "payload = {'account_id':clientlist.name.iloc[0]}\n",
    "response = requests.get(\n",
    "    'https://app.totango.com/api/v2/events/', params=payload, headers=headers)\n",
    "catcherframework = response.json()\n",
    "catcherframework = pd.json_normalize(catcherframework)\n",
    "#df_ = pd.DataFrame(index=catcherframework.index, columns=catcherframework.columns)\n",
    "df_ = pd.DataFrame()\n",
    "#need to clean the initialized df hence the df is dropped to remove multiple NaN rows\n",
    "df_.drop(df_.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:26:59.603167Z",
     "start_time": "2023-07-11T17:26:55.922622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'account_id': 'CSIND00000911'}\n",
      "1 {'account_id': 'CSSGP00000732'}\n",
      "2 {'account_id': 'CSZAF00000728'}\n"
     ]
    }
   ],
   "source": [
    "# time.sleep(65) \n",
    "# Loop over the range from 0 to the length of the clientlist minus 11610\n",
    "for i in range(0, len(clientlist)-1): \n",
    "\n",
    "    # Create a dictionary payload with account_id key and corresponding value from the client list\n",
    "    payload = {'account_id': clientlist.name.iloc[i]}\n",
    "\n",
    "    # Send a GET request to the Totango API with the payload and headers\n",
    "    response = requests.get('https://app.totango.com/api/v2/events/', params=payload, headers=headers)\n",
    "\n",
    "    try:\n",
    "        # Try to convert the response into JSON and normalize it into a flat table\n",
    "        catcher = response.json()\n",
    "        catcher = pd.json_normalize(catcher)\n",
    "\n",
    "        # Concatenate the result with the existing dataframe (df_)\n",
    "        df_ = pd.concat([df_, catcher], sort=False, ignore_index='True')\n",
    "\n",
    "        # Print the index and payload for debugging purposes\n",
    "        print(i, payload)\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there's an error during the JSON parsing, print an error message and continue with the next iteration\n",
    "        print (\"JSON Parsing error detected\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:25:37.783395Z",
     "start_time": "2023-07-11T17:25:37.756312Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The following line converts the timestamp from Totango (which is in Unix time format) to Excel's timestamp.\n",
    "# This is achieved by adding the date difference between Unix Epoch (1970-01-01) and Excel's zero date (1900-01-01, which is 25569 days) \n",
    "# to the Unix time (divided by the number of milliseconds in a day - 86400000, since Unix time is in milliseconds).\n",
    "df_['exceldate'] = (25569 + df_.timestamp.divide(86400000)) \n",
    "\n",
    "# This line converts the Excel date (which is a float number representing the number of days since 1900-01-01) \n",
    "# back to a pandas TimedeltaIndex and adds it to the date 1900-01-01. We subtract one from the exceldate because Excel wrongly \n",
    "# considers 1900 a leap year.\n",
    "df_['date'] = pd.TimedeltaIndex(df_.exceldate-1, unit='d') + datetime.datetime(1900,1,1)\n",
    "\n",
    "# This line extracts only the date part of the datetime object (removing the time component)\n",
    "df_.date = df_.date.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:25:39.665290Z",
     "start_time": "2023-07-11T17:25:39.654319Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#renaming totango field names into a shortened clear name without spaces\n",
    "df_.rename(columns={\n",
    "    'account.display_name': 'display_name',\n",
    "    'account.id': 'account_id',\n",
    "    'alert_content.alert_type':'alert_type',\n",
    "    'alert_content.description':'alert_description',\n",
    "    'alert_content.properties.duration':'alert_duration',\n",
    "    'alert_content.properties.health':'alert_health',\n",
    "    'alert_content.properties.health_prev':'alert_health_prev',\n",
    "    'alert_content.sentiment':'alert_sentiment',\n",
    "    'id':'touchpoint_id',\n",
    "    'note_content.note_id':'note_id',\n",
    "    'note_content.text':'note_text',\n",
    "    'note_content.totango_user.user_name':'note_created_by',\n",
    "    'properties.activity_type_id':'activity_type',\n",
    "    'properties.activity_type_id_is_modified':'is_activity_modified',          \n",
    "    'properties.activity_type_id_prev':'activity_type_prev',                  \n",
    "    'properties.last_edit_time':'last_edit_time',\n",
    "    'properties.last_edit_user':'last_edit_user',                                                                   \n",
    "    'type':'touchpoint_type',                                               \n",
    "    'properties.assets':'assets',                                  \n",
    "    'task_content.action':'task_action',                                \n",
    "    'task_content.assignee.current':'task_current_assignee',\n",
    "    'task_content.assignee.is_modified':'is_task_assignee_modified',                  \n",
    "    'task_content.assigner.current':'task_assigner',                      \n",
    "    'task_content.assigner.is_modified':'is_task_assigner_modified',                  \n",
    "    'task_content.description.current':'task_description',                  \n",
    "    'task_content.description.is_modified':'is_task_desc_modified',               \n",
    "    'task_content.due_date.current':'task_due_date',                      \n",
    "    'task_content.due_date.is_modified':'is_task_due_date_modified',                  \n",
    "    'task_content.last_updater.current':'task_last_updater',                  \n",
    "    'task_content.last_updater.is_modified':'is_task_updater_modified',             \n",
    "    'task_content.origin':'task_origin',                                \n",
    "    'task_content.priority.current':'task_priority',\n",
    "    'task_content.priority.is_modified':'is_task_priority_modified',                  \n",
    "    'task_content.status.current':'task_status',                        \n",
    "    'task_content.status.is_modified':'is_task_status_modified',                    \n",
    "    'task_content.taskAction':'task_action_final',                            \n",
    "    'task_content.task_id':'task_id',\n",
    "    'account.contract_value':'acv',\n",
    "    'task_content.last_updater.prev':'task_last_updater_prev',                     \n",
    "    'task_content.status.prev':'task_status_prev',\n",
    "    'task_content.priority.prev':'task_priority_prev',\n",
    "    'task_content.assignee.prev':'task_assignee_prev',\n",
    "    'task_content.description.prev':'task_description_prev',\n",
    "    'task_content.due_date.prev':'task_due_date_prev'   \n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T17:26:06.027819Z",
     "start_time": "2023-07-11T17:26:06.005809Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#adding refreshed date column\n",
    "df_['refreshed_date']=pd.to_datetime('today')\n",
    "df_['refreshed_date']=df_['refreshed_date'].dt.date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
